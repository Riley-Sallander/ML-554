{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet \n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "ames = pd.read_csv('/Users/rileysallander/Desktop/ML/ML554/Data/AmesHousing.csv')\n",
    "\n",
    "# Get rid of columns with mostly NaN values\n",
    "good_cols = ames.isna().sum() < 100\n",
    "ames = ames.loc[:,good_cols]\n",
    "\n",
    "# Drop other NAs\n",
    "ames = ames.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.11568747, 0.06469903, 0.04562187, 0.22173524, 0.0587554 ]),\n",
       " 'std_fit_time': array([0.05444117, 0.0320529 , 0.0073655 , 0.14743682, 0.01289843]),\n",
       " 'mean_score_time': array([0.02184849, 0.01878839, 0.01478367, 0.02575293, 0.01913934]),\n",
       " 'std_score_time': array([0.00269679, 0.0057675 , 0.00335171, 0.00885727, 0.00300986]),\n",
       " 'param_ridge__alpha': masked_array(data=[0.001, 0.01, 0.1, 1, 10],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'ridge__alpha': 0.001},\n",
       "  {'ridge__alpha': 0.01},\n",
       "  {'ridge__alpha': 0.1},\n",
       "  {'ridge__alpha': 1},\n",
       "  {'ridge__alpha': 10}],\n",
       " 'split0_test_score': array([0.8972854 , 0.89734306, 0.89774358, 0.89815807, 0.8977621 ]),\n",
       " 'split1_test_score': array([0.91040618, 0.91061417, 0.91230557, 0.91744024, 0.92081211]),\n",
       " 'split2_test_score': array([0.78901601, 0.7891259 , 0.79010977, 0.79493606, 0.80057243]),\n",
       " 'split3_test_score': array([0.7721318 , 0.77253192, 0.77576412, 0.78522563, 0.78711955]),\n",
       " 'split4_test_score': array([0.90076168, 0.90131686, 0.90558729, 0.91389818, 0.91509487]),\n",
       " 'mean_test_score': array([0.85392021, 0.85418638, 0.85630206, 0.86193163, 0.86427221]),\n",
       " 'std_test_score': array([0.06027807, 0.06027967, 0.06025049, 0.05910381, 0.0581575 ]),\n",
       " 'rank_test_score': array([5, 4, 3, 2, 1], dtype=int32)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "X = ames.drop([\"SalePrice\", \"Order\", \"PID\"], axis=1)\n",
    "y = ames[\"SalePrice\"]\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [\n",
    "        (\"dummify\", \n",
    "         OneHotEncoder(sparse_output=False, handle_unknown='ignore'),\n",
    "         make_column_selector(dtype_include=object)),\n",
    "        (\"standardize\", \n",
    "         StandardScaler(), \n",
    "         make_column_selector(dtype_include=np.number))\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "ridge_pipeline_1 = Pipeline(\n",
    "    [(\"preprocessing\", ct),\n",
    "     (\"ridge\", Ridge())]\n",
    ")\n",
    "\n",
    "alpha = {'ridge__alpha': (0.001, 0.01, 0.1, 1, 10)}\n",
    "\n",
    "gscv = GridSearchCV(ridge_pipeline_1, alpha, cv=5, scoring='r2')\n",
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "# Display results\n",
    "gscv_fitted.cv_results_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.109e+11, tolerance: 1.348e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.466e+11, tolerance: 1.474e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.894e+11, tolerance: 1.463e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.756e+11, tolerance: 1.407e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.569e+11, tolerance: 1.477e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.110e+11, tolerance: 1.348e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.466e+11, tolerance: 1.474e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.988e+11, tolerance: 1.463e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.757e+11, tolerance: 1.407e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.456e+11, tolerance: 1.477e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.236e+11, tolerance: 1.348e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.570e+11, tolerance: 1.474e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.588e+11, tolerance: 1.463e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.698e+11, tolerance: 1.407e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.557e+11, tolerance: 1.477e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.323e+10, tolerance: 1.477e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([3.19187465, 1.60186996, 1.9111443 , 2.05286527, 1.15308938]),\n",
       " 'std_fit_time': array([0.4751889 , 0.42316385, 0.63628612, 0.33394843, 0.53139451]),\n",
       " 'mean_score_time': array([0.02899694, 0.02146468, 0.01934519, 0.02573667, 0.02895837]),\n",
       " 'std_score_time': array([0.0087486 , 0.01037645, 0.00263982, 0.0036385 , 0.00446341]),\n",
       " 'param_ridge__alpha': masked_array(data=[0.001, 0.01, 0.1, 1, 10],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'ridge__alpha': 0.001},\n",
       "  {'ridge__alpha': 0.01},\n",
       "  {'ridge__alpha': 0.1},\n",
       "  {'ridge__alpha': 1},\n",
       "  {'ridge__alpha': 10}],\n",
       " 'split0_test_score': array([0.8972019 , 0.89720561, 0.89725821, 0.89774385, 0.90077569]),\n",
       " 'split1_test_score': array([0.9103958 , 0.91040134, 0.91045103, 0.91093785, 0.91506699]),\n",
       " 'split2_test_score': array([0.79032004, 0.79085941, 0.79595065, 0.79691806, 0.80141962]),\n",
       " 'split3_test_score': array([0.77402031, 0.77406031, 0.77407171, 0.77426245, 0.77664916]),\n",
       " 'split4_test_score': array([0.90555653, 0.90550225, 0.90535981, 0.90589888, 0.90924976]),\n",
       " 'mean_test_score': array([0.85549892, 0.85560578, 0.85661828, 0.85715222, 0.86063224]),\n",
       " 'std_test_score': array([0.06024221, 0.06010743, 0.05902508, 0.0590181 , 0.05915673]),\n",
       " 'rank_test_score': array([5, 4, 3, 2, 1], dtype=int32)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "X = ames.drop([\"SalePrice\", \"Order\", \"PID\"], axis=1)\n",
    "y = ames[\"SalePrice\"]\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [\n",
    "        (\"dummify\", \n",
    "         OneHotEncoder(sparse_output=False, handle_unknown='ignore'),\n",
    "         make_column_selector(dtype_include=object)),\n",
    "        (\"standardize\", \n",
    "         StandardScaler(), \n",
    "         make_column_selector(dtype_include=np.number))\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "lasso_pipeline_1 = Pipeline(\n",
    "    [(\"preprocessing\", ct),\n",
    "     (\"ridge\", Lasso())]\n",
    ")\n",
    "\n",
    "alpha = {'ridge__alpha': (0.001, 0.01, 0.1, 1, 10)}\n",
    "\n",
    "gscv = GridSearchCV(lasso_pipeline_1, alpha, cv=5, scoring='r2')\n",
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "# Display results\n",
    "gscv_fitted.cv_results_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.516e+11, tolerance: 1.348e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.310e+11, tolerance: 1.474e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.147e+11, tolerance: 1.463e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.395e+11, tolerance: 1.407e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.286e+11, tolerance: 1.477e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.512e+11, tolerance: 1.348e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[30], line 31\u001b[0m\n",
      "\u001b[1;32m     28\u001b[0m alpha \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNet__alpha\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNet__l1_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m)}\n",
      "\u001b[1;32m     30\u001b[0m gscv \u001b[38;5;241m=\u001b[39m GridSearchCV(Net_pipeline_1, alpha, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;32m---> 31\u001b[0m gscv_fitted \u001b[38;5;241m=\u001b[39m gscv\u001b[38;5;241m.\u001b[39mfit(X, y)\n",
      "\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Display results\u001b[39;00m\n",
      "\u001b[1;32m     34\u001b[0m gscv_fitted\u001b[38;5;241m.\u001b[39mcv_results_\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n",
      "\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n",
      "\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n",
      "\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n",
      "\u001b[1;32m   1472\u001b[0m     )\n",
      "\u001b[1;32m   1473\u001b[0m ):\n",
      "\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n",
      "\u001b[1;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n",
      "\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n",
      "\u001b[1;32m    966\u001b[0m     )\n",
      "\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n",
      "\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n",
      "\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n",
      "\u001b[1;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n",
      "\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n",
      "\u001b[1;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m-> 1527\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n",
      "\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n",
      "\u001b[1;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n",
      "\u001b[1;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n",
      "\u001b[1;32m    913\u001b[0m         )\n",
      "\u001b[1;32m    914\u001b[0m     )\n",
      "\u001b[0;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n",
      "\u001b[1;32m    917\u001b[0m     delayed(_fit_and_score)(\n",
      "\u001b[1;32m    918\u001b[0m         clone(base_estimator),\n",
      "\u001b[1;32m    919\u001b[0m         X,\n",
      "\u001b[1;32m    920\u001b[0m         y,\n",
      "\u001b[1;32m    921\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n",
      "\u001b[1;32m    922\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n",
      "\u001b[1;32m    923\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n",
      "\u001b[1;32m    924\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n",
      "\u001b[1;32m    925\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n",
      "\u001b[1;32m    926\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n",
      "\u001b[1;32m    927\u001b[0m     )\n",
      "\u001b[1;32m    928\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n",
      "\u001b[1;32m    929\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n",
      "\u001b[1;32m    930\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n",
      "\u001b[1;32m    931\u001b[0m     )\n",
      "\u001b[1;32m    932\u001b[0m )\n",
      "\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[1;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    939\u001b[0m     )\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n",
      "\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n",
      "\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n",
      "\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n",
      "\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n",
      "\u001b[1;32m     66\u001b[0m )\n",
      "\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n",
      "\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n",
      "\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n",
      "\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n",
      "\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n",
      "\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n",
      "\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n",
      "\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n",
      "\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n",
      "\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n",
      "\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:895\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n",
      "\u001b[1;32m    893\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n",
      "\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m--> 895\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n",
      "\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[1;32m    898\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n",
      "\u001b[1;32m    899\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n",
      "\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n",
      "\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n",
      "\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n",
      "\u001b[1;32m   1472\u001b[0m     )\n",
      "\u001b[1;32m   1473\u001b[0m ):\n",
      "\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py:475\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n",
      "\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;32m    474\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n",
      "\u001b[0;32m--> 475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n",
      "\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n",
      "\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n",
      "\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n",
      "\u001b[1;32m   1472\u001b[0m     )\n",
      "\u001b[1;32m   1473\u001b[0m ):\n",
      "\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:1050\u001b[0m, in \u001b[0;36mElasticNet.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n",
      "\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m   1049\u001b[0m     this_Xy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m-> 1050\u001b[0m _, this_coef, this_dual_gap, this_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath(\n",
      "\u001b[1;32m   1051\u001b[0m     X,\n",
      "\u001b[1;32m   1052\u001b[0m     y[:, k],\n",
      "\u001b[1;32m   1053\u001b[0m     l1_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml1_ratio,\n",
      "\u001b[1;32m   1054\u001b[0m     eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "\u001b[1;32m   1055\u001b[0m     n_alphas\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "\u001b[1;32m   1056\u001b[0m     alphas\u001b[38;5;241m=\u001b[39m[alpha],\n",
      "\u001b[1;32m   1057\u001b[0m     precompute\u001b[38;5;241m=\u001b[39mprecompute,\n",
      "\u001b[1;32m   1058\u001b[0m     Xy\u001b[38;5;241m=\u001b[39mthis_Xy,\n",
      "\u001b[1;32m   1059\u001b[0m     copy_X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "\u001b[1;32m   1060\u001b[0m     coef_init\u001b[38;5;241m=\u001b[39mcoef_[k],\n",
      "\u001b[1;32m   1061\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "\u001b[1;32m   1062\u001b[0m     return_n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "\u001b[1;32m   1063\u001b[0m     positive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive,\n",
      "\u001b[1;32m   1064\u001b[0m     check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "\u001b[1;32m   1065\u001b[0m     \u001b[38;5;66;03m# from here on **params\u001b[39;00m\n",
      "\u001b[1;32m   1066\u001b[0m     tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol,\n",
      "\u001b[1;32m   1067\u001b[0m     X_offset\u001b[38;5;241m=\u001b[39mX_offset,\n",
      "\u001b[1;32m   1068\u001b[0m     X_scale\u001b[38;5;241m=\u001b[39mX_scale,\n",
      "\u001b[1;32m   1069\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n",
      "\u001b[1;32m   1070\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state,\n",
      "\u001b[1;32m   1071\u001b[0m     selection\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselection,\n",
      "\u001b[1;32m   1072\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n",
      "\u001b[1;32m   1073\u001b[0m )\n",
      "\u001b[1;32m   1074\u001b[0m coef_[k] \u001b[38;5;241m=\u001b[39m this_coef[:, \u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;32m   1075\u001b[0m dual_gaps_[k] \u001b[38;5;241m=\u001b[39m this_dual_gap[\u001b[38;5;241m0\u001b[39m]\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n",
      "\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n",
      "\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678\u001b[0m, in \u001b[0;36menet_path\u001b[0;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n",
      "\u001b[1;32m    664\u001b[0m     model \u001b[38;5;241m=\u001b[39m cd_fast\u001b[38;5;241m.\u001b[39menet_coordinate_descent_gram(\n",
      "\u001b[1;32m    665\u001b[0m         coef_,\n",
      "\u001b[1;32m    666\u001b[0m         l1_reg,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    675\u001b[0m         positive,\n",
      "\u001b[1;32m    676\u001b[0m     )\n",
      "\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m precompute \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "\u001b[0;32m--> 678\u001b[0m     model \u001b[38;5;241m=\u001b[39m cd_fast\u001b[38;5;241m.\u001b[39menet_coordinate_descent(\n",
      "\u001b[1;32m    679\u001b[0m         coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
      "\u001b[1;32m    680\u001b[0m     )\n",
      "\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[1;32m    683\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecompute should be one of True, False, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or array-like. Got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    684\u001b[0m         \u001b[38;5;241m%\u001b[39m precompute\n",
      "\u001b[1;32m    685\u001b[0m     )\n",
      "\n",
      "File \u001b[0;32msklearn/linear_model/_cd_fast.pyx:265\u001b[0m, in \u001b[0;36msklearn.linear_model._cd_fast.enet_coordinate_descent\u001b[0;34m()\u001b[0m\n",
      "\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/numpy/core/getlimits.py:484\u001b[0m, in \u001b[0;36mfinfo.__new__\u001b[0;34m(cls, dtype)\u001b[0m\n",
      "\u001b[1;32m    380\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03mfinfo(dtype)\u001b[39;00m\n",
      "\u001b[1;32m    382\u001b[0m \n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    479\u001b[0m \n",
      "\u001b[1;32m    480\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m    482\u001b[0m _finfo_cache \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;32m--> 484\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, dtype):\n",
      "\u001b[1;32m    485\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m    486\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_finfo_cache\u001b[38;5;241m.\u001b[39mget(dtype)  \u001b[38;5;66;03m# most common path\u001b[39;00m\n",
      "\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "X = ames.drop([\"SalePrice\", \"Order\", \"PID\"], axis=1)\n",
    "y = ames[\"SalePrice\"]\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [\n",
    "        (\"dummify\", \n",
    "         OneHotEncoder(sparse_output=False, handle_unknown='ignore'),\n",
    "         make_column_selector(dtype_include=object)),\n",
    "        (\"standardize\", \n",
    "         StandardScaler(), \n",
    "         make_column_selector(dtype_include=np.number))\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "Net_pipeline_1 = Pipeline(\n",
    "    [(\"preprocessing\", ct),\n",
    "     (\"Net\", ElasticNet())]\n",
    ")\n",
    "\n",
    "alpha = {'Net__alpha': (0.001, 0.01, 0.1, 1, 10),'Net__l1_ratio': (0.001, 0.01, 0.1, 1, 10)}\n",
    "\n",
    "gscv = GridSearchCV(Net_pipeline_1, alpha, cv=5, scoring='r2')\n",
    "gscv_fitted = gscv.fit(X, y)\n",
    "\n",
    "# Display results\n",
    "gscv_fitted.cv_results_\n",
    "\n",
    "Net_pipeline_1.named_steps[\"Net\"].coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Net__alpha</th>\n",
       "      <th>Net__l1_ratio</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.863848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.863703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.863688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.863191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.863180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.863061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.860632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.857152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.100</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.856618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.010</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.855606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.855499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.852539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.851718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.851638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.815716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.812489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.812168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.559864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.538557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.536503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>10.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.010</td>\n",
       "      <td>10.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.100</td>\n",
       "      <td>10.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Net__alpha  Net__l1_ratio    scores\n",
       "7        0.010          0.100  0.863848\n",
       "6        0.010          0.010  0.863703\n",
       "5        0.010          0.001  0.863688\n",
       "0        0.001          0.001  0.863191\n",
       "1        0.001          0.010  0.863180\n",
       "2        0.001          0.100  0.863061\n",
       "23      10.000          1.000  0.860632\n",
       "18       1.000          1.000  0.857152\n",
       "13       0.100          1.000  0.856618\n",
       "8        0.010          1.000  0.855606\n",
       "3        0.001          1.000  0.855499\n",
       "12       0.100          0.100  0.852539\n",
       "11       0.100          0.010  0.851718\n",
       "10       0.100          0.001  0.851638\n",
       "17       1.000          0.100  0.815716\n",
       "16       1.000          0.010  0.812489\n",
       "15       1.000          0.001  0.812168\n",
       "22      10.000          0.100  0.559864\n",
       "21      10.000          0.010  0.538557\n",
       "20      10.000          0.001  0.536503\n",
       "4        0.001         10.000       NaN\n",
       "9        0.010         10.000       NaN\n",
       "14       0.100         10.000       NaN\n",
       "19       1.000         10.000       NaN\n",
       "24      10.000         10.000       NaN"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degrees = pd.DataFrame(gscv_fitted.cv_results_[\"params\"])\n",
    "results = degrees.assign(scores=gscv_fitted.cv_results_['mean_test_score'])\n",
    "results.sort_values(by='scores', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -3274.06371953,   2831.31364917,   -560.81274667,   2568.50868923,   2274.29131138,  -3839.23718643,\n",
       "        -4104.59397572,   4104.59397493,   1375.66776387,   5836.45071372,  -8665.63548494,   1453.29481961,\n",
       "       -10543.7702177 ,   8625.3977008 ,   -925.41609439,   2843.78861498,   1446.05578542,  -1110.99069061,\n",
       "         -334.95398366,   -338.58158775,   6769.35308915,  -4913.57501818,  -1877.92064258,    360.83527863,\n",
       "        -1019.47698425,   4425.90721051,  -3406.31912278,  -3751.24594771,   1089.73898583,   2952.23756061,\n",
       "         1552.0536169 ,  -2357.39556637,  -7600.69697268,   9009.20976462, -12460.61386716,  -9677.59028391,\n",
       "          461.18565423,   5155.63189475,  -3614.62708697,   -184.3357141 ,   1102.62949743,  -7479.02742932,\n",
       "        -8466.55964002,   2295.17864077, -10598.52795124,  22550.95345979,  18488.23528155,  -6478.62083832,\n",
       "        -4115.7655382 ,  -3935.19069084,  -7367.08158793,   6964.71960391,  23094.65850408,  -4697.59772732,\n",
       "        -1931.11117139,  -1994.10439211,  -3931.50417824,   5792.14796901,   5417.78649698,   3269.967972  ,\n",
       "        -4029.0399316 ,     83.9420208 ,  -1979.22695443,  -2629.85788472,    738.13339864,   -544.10494079,\n",
       "          112.60288461,   8510.80759418, -10956.9474835 ,   1610.36815714,    238.3797157 ,    290.31623132,\n",
       "         6272.21000293,   7344.90774445,  -1174.578123  ,  -7759.33570184,  -4683.09280942,  -1874.68580248,\n",
       "         2699.82686001,   5935.72029667,  -1300.10862605,   -961.03356094,  -6354.2557012 ,   3827.47739034,\n",
       "        -1972.71868019,  -2036.98856952,    733.84866292,   1006.10803734,   2703.73465141,  -3039.98371036,\n",
       "          633.05873368, -16853.27289508,   2507.94815437,    980.05133935,    651.95312784,    219.96426661,\n",
       "         -168.65416283,  -1757.33842657,  14419.12637244,   -774.33100797,    795.40457533,   1330.21813671,\n",
       "        12219.86248542,   -390.08719576,   1077.85477993,  -3714.02596706,   -631.71555876,    111.89638986,\n",
       "         -597.31631739,   2730.1838654 ,   -620.02020862,  -6501.92426242,  -2629.42044747,  -1221.31234579,\n",
       "        -1184.82245652,  -1070.21036249,   1289.80724226,    394.52220939,   -200.80092625,   -390.08719581,\n",
       "          651.04439302,    212.57345913,   4899.37898393,    293.64688446,    -81.95444144,  -2818.2265545 ,\n",
       "         2730.1838654 ,   -816.93032044,  -3943.13042975,   2173.87624639,   -800.81011528,  -2522.77174864,\n",
       "        12998.193703  ,   -396.87551425,  -4634.77748302,  -7966.31846931,    -79.22825011,  -2037.08534858,\n",
       "          956.51430835,   -325.85645764,   1485.76685253,  -2152.8058597 ,  -1094.35789495,   2419.36539998,\n",
       "         2311.05648746,  -1483.14700792,  14748.88902253,  -2744.51802855,  -6366.36431069,   -284.60526013,\n",
       "        -5353.06803457,   -487.68730057,    450.72025335,   -827.24966282,    599.50119692,    264.60440381,\n",
       "         1423.6349609 ,  10891.32204761,  -5662.02451622,  -6652.93249164,   1427.55253716,    510.06437226,\n",
       "         4579.0430989 ,  -3645.04003042,  -1546.29952267,  -1325.3204157 ,   3971.52554878,  -2182.80167503,\n",
       "         3325.26020839,  -3345.84566156,  -2682.89800109,    914.75958498,   1184.14018487,   1013.74773615,\n",
       "          418.31293299,  -2616.42307691,   2574.95243539,  -2125.57439994,    864.45877842,  -1132.68095275,\n",
       "         -181.04475377,   1089.92835936,  -1089.92836026,    295.37153153,   -624.96879172,    416.77243592,\n",
       "           37.68905531,   -124.97534251,  16175.6707277 ,  -3757.02915982,  -6005.0669732 ,    473.3743459 ,\n",
       "        -6886.83776804,  -3279.7498057 ,  -2800.65111742,    388.12989279,    351.20140511,   -572.29248768,\n",
       "         -299.2997199 ,  -2094.81873395,   8307.70282793,    253.00679065,   -961.76600734,    708.64809559,\n",
       "        -5448.27005638,   -295.11725071,   4325.29248103,   1504.01179   ,   -844.02988417,   -346.62434816,\n",
       "         3355.13231832,    506.91009514,   -375.94293706,  -2381.13997966,  -5945.69265507,   3038.57269771,\n",
       "         2506.10964049,  -3564.11878457,    918.83735989,   3046.06950977,  -4445.89935975,   3402.01686811,\n",
       "        13295.76641865,   5703.4629909 ,   7056.71315446,   1813.84510061,   2863.57660771,   3032.25407876,\n",
       "         1305.83847637,  -1068.36865975,   2798.05139125,   7216.5567204 ,  11106.0526777 ,    282.34348951,\n",
       "        15018.57457805,   2465.39803823,   -696.30009499,   2934.30830922,   1923.55304095,  -1878.71413791,\n",
       "        -1985.78974782,   1815.96351624,   2963.45935594,   4553.68036601,   1437.16788177,   1461.79915449,\n",
       "         -916.78558579,    916.63428105,    162.41080914,   3139.95251528,    289.8843009 ,  -4229.62433145,\n",
       "         -564.88701484,   -971.43969776])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "X = ames.drop([\"SalePrice\", \"Order\", \"PID\"], axis=1)\n",
    "y = ames[\"SalePrice\"]\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [\n",
    "        (\"dummify\", \n",
    "         OneHotEncoder(sparse_output=False, handle_unknown='ignore'),\n",
    "         make_column_selector(dtype_include=object)),\n",
    "        (\"standardize\", \n",
    "         StandardScaler(), \n",
    "         make_column_selector(dtype_include=np.number))\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "Net_pipeline_fin = Pipeline(\n",
    "    [(\"preprocessing\", ct),\n",
    "     (\"Net\", ElasticNet(alpha=0.01, l1_ratio= 0.1))]\n",
    ")\n",
    "\n",
    "\n",
    "Net_pipeline_fin.fit(X,y)\n",
    "Net_pipeline_fin.named_steps[\"Net\"].coef_"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
